{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 5: Google Speech Commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import wave\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Conv1D, AvgPool1D, MaxPool1D, ZeroPadding1D, BatchNormalization, Flatten, Dense, Activation\n",
    "from keras.activations import softmax\n",
    "from keras.utils import get_file\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download, cache and extract Google Speech Commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = Path('datasets')\n",
    "if not (dataset_dir/'testing_list.txt').exists(): # Assume dataset already downloaded/extracted if testing list is present\n",
    "    get_file(None, \"http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz\",\n",
    "                    extract=True,\n",
    "                    file_hash=\"6b74f3901214cb2c2934e98196829835\",\n",
    "                    cache_dir='.',\n",
    "                    cache_subdir=dataset_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load raw spoken digits data from Google Speech Commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classes to handle, ordered by label\n",
    "CLASSES = ['zero', 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine']\n",
    "\n",
    "with (dataset_dir/'testing_list.txt').open() as f:\n",
    "    testing_list = f.read().splitlines()\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for recording in dataset_dir.glob(f'**/*.wav'):\n",
    "    if not recording.parent.name in CLASSES: # Ignore unused classes\n",
    "        continue\n",
    "    label = CLASSES.index(recording.parent.name) # Assign class number\n",
    "    \n",
    "    with wave.open(str(recording)) as f: # Read wave file\n",
    "        data = np.frombuffer(f.readframes(f.getnframes()), dtype=np.int16).copy() # As 16-bit signed integer\n",
    "        \n",
    "    data = data.astype(np.float32) # Convert to 32-bit floating-point\n",
    "    data.resize((16000, 1)) # Resize to 1s (16kHz) with zero-padding, 1 channel\n",
    "\n",
    "    if str(recording.relative_to(dataset_dir)) in testing_list: # Assign to test set if file in test list\n",
    "        x_test.append(data)\n",
    "        y_test.append(label)\n",
    "    else:\n",
    "        x_train.append(data)\n",
    "        y_train.append(label)\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "y_train = to_categorical(np.array(y_train))\n",
    "x_test = np.array(x_test)\n",
    "y_test = to_categorical(np.array(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare for inference with fixed-point Q7.9 samples by scaling input data accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIXED_POINT = 9\n",
    "x_train /= 2**FIXED_POINT\n",
    "x_test  /= 2**FIXED_POINT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export small dataset (250 random vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perms = np.random.permutation(len(y_test))[0:250]\n",
    "x_test_250 = x_test[perms]\n",
    "y_test_250 = y_test[perms]\n",
    "np.savetxt('x_test_gsc_250.csv', x_test_250.reshape((x_test_250.shape[0], -1)), delimiter=',', fmt='%s')\n",
    "np.savetxt('y_test_gsc_250.csv', y_test_250, delimiter=',', fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Build model M5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=(16000, 1)))\n",
    "# TODO: fill model architecture\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=len(CLASSES)))\n",
    "model.add(Activation('softmax')) # SoftMax activation needs to be separate from Dense to remove it later on\n",
    "# EXPLORE Learning Rate\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=10e-3)\n",
    "model.summary()\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, epochs=50, batch_size=384, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test, verbose=2)\n",
    "pred_test = model.predict(x_test)\n",
    "print(tf.math.confusion_matrix(y_test.argmax(axis=1), pred_test.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluate model on small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test_250, y_test_250, verbose=2)\n",
    "pred_test_250 = model.predict(x_test_250)\n",
    "print(tf.math.confusion_matrix(y_test_250.argmax(axis=1), pred_test_250.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('lab_gsc.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove SoftMax layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(model.layers[-1], Activation) and model.layers[-1].activation == softmax:\n",
    "    model = tf.keras.Model(model.input, model.layers[-2].output, name=model.name)\n",
    "else:\n",
    "    print('Error: last layer is not SoftMax Activation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Qualia-CodeGen for C inference code generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install qualia_codegen_core\n",
    "import qualia_codegen_core\n",
    "from qualia_codegen_core.graph.KerasModelGraph import KerasModelGraph\n",
    "from qualia_codegen_core.graph.Quantization import Quantization\n",
    "from qualia_codegen_core.graph.RoundMode import RoundMode\n",
    "\n",
    "from importlib.resources import files\n",
    "main_path = str((files('qualia_codegen_core.examples')/'Linux'/'main.cpp').resolve())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Keras Model to Qualia-CodeGen's internal representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelgraph = KerasModelGraph(model).convert()\n",
    "print(modelgraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate C code for the trained model with 32-bit floating-point representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_modelgraph = copy.deepcopy(modelgraph)\n",
    "\n",
    "# layer quantization annotations for float32\n",
    "for node in float_modelgraph.nodes:\n",
    "    # No scale factor if not fixed-point quantization on integers\n",
    "    node.q = Quantization(\n",
    "            number_type=float,\n",
    "            width=32,\n",
    "            long_width=32,\n",
    "            weights_scale_factor=0,\n",
    "            output_scale_factor=0,\n",
    "            weights_round_mode=RoundMode.NONE,\n",
    "            output_round_mode=RoundMode.NONE,\n",
    "            )\n",
    "\n",
    "float_res = qualia_codegen_core.Converter(output_path=Path('gsc_output_floating')).convert_model(float_modelgraph)\n",
    "\n",
    "with open('gsc_model_floating.h', 'w') as f:\n",
    "    f.write(float_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the 32-bit floating-point C code for x86 and evaluate on small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!g++ -std=c++17 -Wall -Wextra -pedantic -Ofast -o gsc_floating -include gsc_output_floating/include/defines.h -Igsc_output_floating/include gsc_output_floating/model.c {main_path}\n",
    "!./gsc_floating x_test_gsc_250.csv y_test_gsc_250.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Generate C code for the trained model with 16-bit fixed-point representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_modelgraph = copy.deepcopy(modelgraph)\n",
    "\n",
    "# layer quantization annotations for int16 Q9.7\n",
    "for node in fixed_modelgraph.nodes:\n",
    "    node.q = Quantization(\n",
    "            number_type=int,\n",
    "            width=16,\n",
    "            long_width=32,\n",
    "            weights_scale_factor=7,\n",
    "            output_scale_factor=7,\n",
    "            weights_round_mode=RoundMode.FLOOR,\n",
    "            output_round_mode=RoundMode.FLOOR,\n",
    "            )\n",
    "\n",
    "fixed_res = qualia_codegen_core.Converter(output_path=Path('gsc_output_fixed')).convert_model(fixed_modelgraph)\n",
    "\n",
    "with open('gsc_model_fixed.h', 'w') as f:\n",
    "    f.write(fixed_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Compile the 16-bit fixed-point C code for x86 and evaluate on small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!g++ -std=c++17 -Wall -Wextra -pedantic -Ofast -o gsc_fixed -include gsc_output_fixed/include/defines.h -Igsc_output_fixed/include gsc_output_fixed/model.c {main_path}\n",
    "!./gsc_fixed x_test_gsc_250.csv y_test_gsc_250.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
