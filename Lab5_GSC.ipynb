{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 5: Google Speech Commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import wave\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Conv1D, AvgPool1D, MaxPool1D, ZeroPadding1D, BatchNormalization, Flatten, Dense, Activation\n",
    "from keras.activations import softmax\n",
    "from keras.utils import get_file\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import os\n",
    "\n",
    "import wave \n",
    "import xenocanto\n",
    "import random\n",
    "\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "birds = ['Yellowhammer','SpottedFlycatcher','CommonCuckoo','CirlBunting']\n",
    "dataset_dir = Path('dataset')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download, and store cirds recordings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving metadata...\n",
      "Downloading metadata page 1...\n",
      "Metadata retrieval complete.\n",
      "Retrieving metadata...\n",
      "Downloading metadata page 1...\n",
      "Metadata retrieval complete.\n",
      "Retrieving metadata...\n",
      "Downloading metadata page 1...\n",
      "Metadata retrieval complete.\n",
      "313 recordings found, downloading...\n",
      "Creating recording folder at dataset/audio/CirlBunting/\n",
      "Download complete.\n",
      "Retrieving metadata...\n",
      "Downloading metadata page 1...\n",
      "Metadata retrieval complete.\n",
      "234 recordings found, downloading...\n",
      "Download complete.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if not (dataset_dir/'audio/testing_list.txt').exists(): # Assume dataset already downloaded/extracted if testing list is present\n",
    "    for bird in birds : \n",
    "        xenocanto.metadata([bird,\"type:song\",\"q:A\"])\n",
    "        xenocanto.metadata([bird,\"type:song\",\"q:B\"])\n",
    "        await xenocanto.download([bird,\"type:song\",\"q:A\"],2)\n",
    "        await xenocanto.download([bird,\"type:song\",\"q:B\"],2)\n",
    "        if bird == 'Muscicapa striata' :\n",
    "            xenocanto.metadata([bird,\"type:song\",\"q:C\"])\n",
    "            await xenocanto.download([bird,\"type:song\",\"q:C\"],2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fitting the records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_audio_file(audio_file_path, output_folder, output_file_name, split_length=1):\n",
    "    # if filename starts with splitted_ then skip\n",
    "    if output_file_name.startswith(\"splitted_\"):\n",
    "        print(\"file already splitted, skipping\")\n",
    "        return\n",
    "    if any(\"splitted_\"+output_file_name in f for f in os.listdir(output_folder)):\n",
    "        print(\"file already exists, skipping\")\n",
    "        return\n",
    "    audio_signal, sample_rate = librosa.load(audio_file_path, sr=None)\n",
    "\n",
    "    len_audio_signal = len(audio_signal)\n",
    "\n",
    "    split_length_samples = split_length * sample_rate\n",
    "    audio_signal = audio_signal[:len_audio_signal - len_audio_signal % split_length_samples]\n",
    "    if len(audio_signal) > split_length:\n",
    "        audio_signal = np.split(audio_signal, len(audio_signal) / split_length_samples)\n",
    "\n",
    "    number_of_files = str(int(len_audio_signal / sample_rate))\n",
    "    for index, y_split in enumerate(audio_signal):\n",
    "        sf.write(\n",
    "            os.path.join(output_folder,\n",
    "                         \"splitted_\" + output_file_name + \"_\" + str(index + 1) + \"_of_\" + number_of_files + \".wav\"),\n",
    "            y_split, sample_rate)\n",
    "    #os.remove(audio_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# chosing training Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/audio/CirlBunting\n",
      "dataset/audio/Yellowhammer\n",
      "dataset/audio/SpottedFlycatcher\n",
      "dataset/audio/CommonCuckoo\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# create train, test and text pointers\n",
    "recordings_folder = \"dataset/audio\"\n",
    "main_bird = \"Yellowhammer\"\n",
    "\n",
    "file_name = \"testing_list.txt\"\n",
    "\n",
    "count = 0\n",
    "with open(os.path.join(recordings_folder, file_name), \"w\", encoding=\"utf-8\") as f:\n",
    "    for bird_type in os.listdir(recordings_folder):\n",
    "        \n",
    "        bird_folder = os.path.join(recordings_folder, bird_type)\n",
    "        if os.path.isdir(bird_folder) and bird_folder != \"dataset/audio/.ipynb_checkpoints\":\n",
    "            print(bird_folder)\n",
    "            for recording in os.listdir(bird_folder):\n",
    "                sound_filename = os.path.join(bird_folder, recording)\n",
    "                if os.path.isfile(sound_filename) and \"splitted_\" in sound_filename:\n",
    "                    if np.random.rand() > 0.3:\n",
    "                        f.write(sound_filename + \"\\n\")\n",
    "                        count += 1\n",
    "                        \n",
    "    ratio = count / len(os.listdir(os.path.join(recordings_folder, main_bird.replace(\" \", \"_\"))))\n",
    "    number_of_main_bird_recordings = count / (\n",
    "                sum(os.path.isdir(os.path.join(recordings_folder, f)) for f in os.listdir(recordings_folder)) - 1)\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for recording in os.listdir(os.path.join(recordings_folder, main_bird.replace(\" \", \"_\"))):\n",
    "        if count > number_of_main_bird_recordings:\n",
    "            break\n",
    "\n",
    "        # if random number between 0 and 1 is greater than 0.3 then add to testing_list.txt\n",
    "        if np.random.rand() > ratio:\n",
    "            count += 1\n",
    "            f.write(os.path.join(recordings_folder, main_bird.replace(\" \", \"_\"), recording) + \"\\n\")\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"splitting audio into multiple recordings\")\n",
    "for bird_type in os.listdir(recordings_folder):\n",
    "\n",
    "    bird_folder = os.path.join(recordings_folder, bird_type)\n",
    "    if os.path.isdir(bird_folder) and bird_folder != \"dataset/audio/.ipynb_checkpoints\":\n",
    "        print(\"looking into folder:\", bird_folder)\n",
    "        number_of_recordings = len(os.listdir(bird_folder))\n",
    "        limit = 200\n",
    "        for index, recording in enumerate(os.listdir(bird_folder)):\n",
    "            if index == limit: \n",
    "                break\n",
    "            print(\"splitting recording\", str(index+1), recording, \"out of\", number_of_recordings, \"for bird\", bird_type)\n",
    "            recording_path = os.path.join(bird_folder, recording)\n",
    "            split_audio_file(recording_path, bird_folder, recording.split(\".\")[0], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = Path('dataset/audio')\n",
    "\n",
    "CLASSES = birds\n",
    "\n",
    "with (dataset_dir/ 'testing_list.txt').open(encoding='utf-8') as f:\n",
    "    testing_list = f.read().splitlines()\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "x_test = []\n",
    "y_test = []\n",
    "for recording in dataset_dir.glob('**/*.wav'):\n",
    "    if not recording.parent.name in CLASSES:\n",
    "        continue\n",
    "    if \"splitted_\" not in str(recording):\n",
    "        continue\n",
    "    label = CLASSES.index(recording.parent.name)\n",
    "\n",
    "    with wave.open(str(recording)) as f :\n",
    "        data = np.frombuffer(f.readframes(f.getnframes()), dtype=np.int16).copy()\n",
    "\n",
    "    data = data.astype(np.float32)\n",
    "    data.resize((16000, 1))\n",
    "    if \"splitted_\" in str(recording):\n",
    "        if str(recording) in testing_list:\n",
    "            x_train.append(data)\n",
    "            y_train.append(label)\n",
    "        elif y_train.count(label) < 2400:\n",
    "            x_test.append(data)\n",
    "            y_test.append(label)\n",
    "x_train = np.array(x_train)\n",
    "y_train = to_categorical(np.array(y_train))\n",
    "x_test = np.array(x_test)\n",
    "y_test = to_categorical(np.array(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4102, 16000, 1)\n",
      "(4102, 4)\n",
      "(13087, 16000, 1)\n",
      "(13087, 4)\n"
     ]
    }
   ],
   "source": [
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mean = x_train.mean()\n",
    "x_std = x_train.std()\n",
    "\n",
    "x_train -= x_mean\n",
    "x_test -= x_mean\n",
    "x_train /= x_std\n",
    "x_test /= x_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('x_test.csv', x_test.reshape(x_test.shape[0], -1), delimiter=',', fmt='%s')\n",
    "np.savetxt('y_test.csv', y_test, delimiter=',', fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " max_pooling1d_4 (MaxPoolin  (None, 800, 1)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 761, 8)            328       \n",
      "                                                                 \n",
      " max_pooling1d_5 (MaxPoolin  (None, 190, 8)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 188, 16)           400       \n",
      "                                                                 \n",
      " max_pooling1d_6 (MaxPoolin  (None, 47, 16)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 45, 32)            1568      \n",
      "                                                                 \n",
      " max_pooling1d_7 (MaxPoolin  (None, 11, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " average_pooling1d_1 (Avera  (None, 1, 32)             0         \n",
      " gePooling1D)                                                    \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 132       \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 4)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2428 (9.48 KB)\n",
      "Trainable params: 2428 (9.48 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Modifier\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(16000, 1)))\n",
    "model.add(MaxPool1D(pool_size=20, padding='valid'))\n",
    "model.add(Conv1D(filters=8, kernel_size=40, activation='relu'))\n",
    "model.add(MaxPool1D(pool_size=4, padding='valid'))\n",
    "model.add(Conv1D(filters=16, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPool1D(pool_size=4, padding='valid'))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPool1D(pool_size=4, padding='valid'))\n",
    "model.add(AvgPool1D(pool_size=8))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=4))\n",
    "model.add(Activation('softmax'))  # SoftMax activation needs to be separate from Dense to remove it later on\n",
    "# EXPLORE Learning Rate\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=10e-4)\n",
    "model.summary()\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-27 16:44:01.981289: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 837568000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "131/131 [==============================] - 9s 66ms/step - loss: 1.1216 - categorical_accuracy: 0.5089 - val_loss: 1.1860 - val_categorical_accuracy: 0.4629\n",
      "Epoch 2/20\n",
      "131/131 [==============================] - 7s 52ms/step - loss: 1.1086 - categorical_accuracy: 0.5145 - val_loss: 1.1512 - val_categorical_accuracy: 0.4954\n",
      "Epoch 3/20\n",
      "131/131 [==============================] - 7s 50ms/step - loss: 1.1018 - categorical_accuracy: 0.5165 - val_loss: 1.1944 - val_categorical_accuracy: 0.4564\n",
      "Epoch 4/20\n",
      "131/131 [==============================] - 7s 51ms/step - loss: 1.0929 - categorical_accuracy: 0.5224 - val_loss: 1.1869 - val_categorical_accuracy: 0.4725\n",
      "Epoch 5/20\n",
      "131/131 [==============================] - 7s 50ms/step - loss: 1.0861 - categorical_accuracy: 0.5239 - val_loss: 1.1896 - val_categorical_accuracy: 0.4861\n",
      "Epoch 6/20\n",
      "131/131 [==============================] - 7s 54ms/step - loss: 1.0792 - categorical_accuracy: 0.5273 - val_loss: 1.1439 - val_categorical_accuracy: 0.4759\n",
      "Epoch 7/20\n",
      "131/131 [==============================] - 7s 50ms/step - loss: 1.0770 - categorical_accuracy: 0.5273 - val_loss: 1.1166 - val_categorical_accuracy: 0.5132\n",
      "Epoch 8/20\n",
      "131/131 [==============================] - 7s 50ms/step - loss: 1.0734 - categorical_accuracy: 0.5292 - val_loss: 1.1414 - val_categorical_accuracy: 0.4798\n",
      "Epoch 9/20\n",
      "131/131 [==============================] - 7s 50ms/step - loss: 1.0694 - categorical_accuracy: 0.5324 - val_loss: 1.1309 - val_categorical_accuracy: 0.5171\n",
      "Epoch 10/20\n",
      "131/131 [==============================] - 7s 50ms/step - loss: 1.0678 - categorical_accuracy: 0.5317 - val_loss: 1.1410 - val_categorical_accuracy: 0.4569\n",
      "Epoch 11/20\n",
      "131/131 [==============================] - 7s 50ms/step - loss: 1.0642 - categorical_accuracy: 0.5350 - val_loss: 1.1272 - val_categorical_accuracy: 0.4817\n",
      "Epoch 12/20\n",
      "131/131 [==============================] - 6s 50ms/step - loss: 1.0657 - categorical_accuracy: 0.5356 - val_loss: 1.1939 - val_categorical_accuracy: 0.4410\n",
      "Epoch 13/20\n",
      "131/131 [==============================] - 6s 49ms/step - loss: 1.0601 - categorical_accuracy: 0.5394 - val_loss: 1.1406 - val_categorical_accuracy: 0.4912\n",
      "Epoch 14/20\n",
      "131/131 [==============================] - 7s 51ms/step - loss: 1.0539 - categorical_accuracy: 0.5383 - val_loss: 1.1190 - val_categorical_accuracy: 0.4976\n",
      "Epoch 15/20\n",
      "131/131 [==============================] - 7s 51ms/step - loss: 1.0523 - categorical_accuracy: 0.5395 - val_loss: 1.1230 - val_categorical_accuracy: 0.5129\n",
      "Epoch 16/20\n",
      "131/131 [==============================] - 7s 50ms/step - loss: 1.0522 - categorical_accuracy: 0.5387 - val_loss: 1.1012 - val_categorical_accuracy: 0.5307\n",
      "Epoch 17/20\n",
      "131/131 [==============================] - 6s 49ms/step - loss: 1.0456 - categorical_accuracy: 0.5437 - val_loss: 1.1342 - val_categorical_accuracy: 0.4851\n",
      "Epoch 18/20\n",
      "131/131 [==============================] - 7s 50ms/step - loss: 1.0436 - categorical_accuracy: 0.5445 - val_loss: 1.0928 - val_categorical_accuracy: 0.5129\n",
      "Epoch 19/20\n",
      "131/131 [==============================] - 7s 50ms/step - loss: 1.0427 - categorical_accuracy: 0.5431 - val_loss: 1.0792 - val_categorical_accuracy: 0.5268\n",
      "Epoch 20/20\n",
      "131/131 [==============================] - 7s 50ms/step - loss: 1.0426 - categorical_accuracy: 0.5473 - val_loss: 1.0975 - val_categorical_accuracy: 0.5215\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f9f16ab3350>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=20, batch_size=100, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 - 1s - loss: 1.0975 - categorical_accuracy: 0.5215 - 1s/epoch - 11ms/step\n",
      "129/129 [==============================] - 3s 13ms/step\n",
      "tf.Tensor(\n",
      "[[830 119  34  49]\n",
      " [475 445  45  86]\n",
      " [178 122 649  81]\n",
      " [563 150  61 215]], shape=(4, 4), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, verbose=2)\n",
    "pred_test = model.predict(x_test)\n",
    "print(tf.math.confusion_matrix(y_test.argmax(axis=1), pred_test.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(model.input, model.layers[-2].output, name=model.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('lab_gsc.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove SoftMax layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load the model\n",
    "model = load_model('lab_gsc.h5')\n",
    "if isinstance(model.layers[-1], Activation) and model.layers[-1].activation == softmax:\n",
    "    model = tf.keras.Model(model.input, model.layers[-2].output, name=model.name)\n",
    "else:\n",
    "    print('Error: last layer is not SoftMax Activation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Qualia-CodeGen for C inference code generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting qualia_codegen_core\n",
      "  Downloading qualia_codegen_core-2.2.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from qualia_codegen_core) (1.24.4)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from qualia_codegen_core) (3.1.2)\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.11/site-packages (from qualia_codegen_core) (4.8.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->qualia_codegen_core) (2.1.3)\n",
      "Downloading qualia_codegen_core-2.2.0-py3-none-any.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hInstalling collected packages: qualia_codegen_core\n",
      "Successfully installed qualia_codegen_core-2.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot find PyTorch, PyTorch framework will be unavailable\n"
     ]
    }
   ],
   "source": [
    "%pip install qualia_codegen_core\n",
    "import qualia_codegen_core\n",
    "from qualia_codegen_core.graph.KerasModelGraph import KerasModelGraph\n",
    "from qualia_codegen_core.graph.Quantization import Quantization\n",
    "from qualia_codegen_core.graph.RoundMode import RoundMode\n",
    "\n",
    "from importlib.resources import files\n",
    "main_path = str((files('qualia_codegen_core.examples')/'Linux'/'main.cpp').resolve())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Keras Model to Qualia-CodeGen's internal representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "—————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "Inputs                                           | Layer                                            | Outputs                                          | Input shape                                      | Output shape                                    \n",
      "—————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————\n",
      "                                                 | input_2                                          | max_pooling1d_4                                  | (1, 16000, 1)                                    | ((1, 16000, 1),)                                \n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "input_2                                          | max_pooling1d_4                                  | conv1d_3                                         | (1, 16000, 1)                                    | ((1, 800, 1),)                                  \n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "max_pooling1d_4                                  | conv1d_3                                         | max_pooling1d_5                                  | (1, 800, 1)                                      | ((1, 761, 8),)                                  \n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "conv1d_3                                         | max_pooling1d_5                                  | conv1d_4                                         | (1, 761, 8)                                      | ((1, 190, 8),)                                  \n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "max_pooling1d_5                                  | conv1d_4                                         | max_pooling1d_6                                  | (1, 190, 8)                                      | ((1, 188, 16),)                                 \n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "conv1d_4                                         | max_pooling1d_6                                  | conv1d_5                                         | (1, 188, 16)                                     | ((1, 47, 16),)                                  \n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "max_pooling1d_6                                  | conv1d_5                                         | max_pooling1d_7                                  | (1, 47, 16)                                      | ((1, 45, 32),)                                  \n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "conv1d_5                                         | max_pooling1d_7                                  | average_pooling1d_1                              | (1, 45, 32)                                      | ((1, 11, 32),)                                  \n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "max_pooling1d_7                                  | average_pooling1d_1                              | flatten_1                                        | (1, 11, 32)                                      | ((1, 1, 32),)                                   \n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "average_pooling1d_1                              | flatten_1                                        | dense_1                                          | (1, 1, 32)                                       | ((1, 32),)                                      \n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "flatten_1                                        | dense_1                                          |                                                  | (1, 32)                                          | ((1, 4),)                                       \n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelgraph = KerasModelGraph(model).convert()\n",
    "print(modelgraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate C code for the trained model with 32-bit floating-point representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Graphviz not available\n"
     ]
    }
   ],
   "source": [
    "float_modelgraph = copy.deepcopy(modelgraph)\n",
    "\n",
    "# layer quantization annotations for float32\n",
    "for node in float_modelgraph.nodes:\n",
    "    # No scale factor if not fixed-point quantization on integers\n",
    "    node.q = Quantization(\n",
    "            number_type=float,\n",
    "            width=32,\n",
    "            long_width=32,\n",
    "            weights_scale_factor=0,\n",
    "            output_scale_factor=0,\n",
    "            weights_round_mode=RoundMode.NONE,\n",
    "            output_round_mode=RoundMode.NONE,\n",
    "            )\n",
    "\n",
    "float_res = qualia_codegen_core.Converter(output_path=Path('gsc_output_floating')).convert_model(float_modelgraph)\n",
    "\n",
    "with open('gsc_model_floating.h', 'w') as f:\n",
    "    f.write(float_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the 32-bit floating-point C code for x86 and evaluate on small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!g++ -std=c++17 -Wall -Wextra -pedantic -Ofast -o gsc_floating -include gsc_output_floating/include/defines.h -Igsc_output_floating/include gsc_output_floating/model.c {main_path}\n",
    "!./gsc_floating x_test_gsc_250.csv y_test_gsc_250.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Generate C code for the trained model with 16-bit fixed-point representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Graphviz not available\n"
     ]
    }
   ],
   "source": [
    "fixed_modelgraph = copy.deepcopy(modelgraph)\n",
    "\n",
    "# layer quantization annotations for int16 Q9.7\n",
    "for node in fixed_modelgraph.nodes:\n",
    "    node.q = Quantization(\n",
    "            number_type=int,\n",
    "            width=16,\n",
    "            long_width=32,\n",
    "            weights_scale_factor=7,\n",
    "            output_scale_factor=7,\n",
    "            weights_round_mode=RoundMode.FLOOR,\n",
    "            output_round_mode=RoundMode.FLOOR,\n",
    "            )\n",
    "\n",
    "fixed_res = qualia_codegen_core.Converter(output_path=Path('gsc_output_fixed')).convert_model(fixed_modelgraph)\n",
    "\n",
    "with open('gsc_model_fixed.h', 'w') as f:\n",
    "    f.write(fixed_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Compile the 16-bit fixed-point C code for x86 and evaluate on small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy: 0.477328\n"
     ]
    }
   ],
   "source": [
    "!g++ -std=c++17 -Wall -Wextra -pedantic -Ofast -o gsc_fixed -include gsc_output_fixed/include/defines.h -Igsc_output_fixed/include gsc_output_fixed/model.c {main_path}\n",
    "!./gsc_fixed x_test.csv y_test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
